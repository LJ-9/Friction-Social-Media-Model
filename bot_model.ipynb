{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VdiGhQd57n1"
   },
   "source": [
    "Code to (re)produce results in the paper \n",
    "\"Manipulating the Online Marketplace of Ideas\" \n",
    "by Xiaodan Lou, Alessandro Flammini, and Filippo Menczer\n",
    "https://arxiv.org/abs/1907.06130\n",
    "\n",
    "Notes:\n",
    "* Need Python 3.6 or later; eg: `module load python/3.6.6`\n",
    "* Remember link direction is following, opposite of info spread!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T15:21:42.454586Z",
     "start_time": "2020-05-25T15:21:40.763176Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "byMDogYTqly4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import random\n",
    "import numpy\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import fcntl\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T15:21:47.830099Z",
     "start_time": "2020-05-25T15:21:47.824017Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xFWqYkRp5uHr"
   },
   "outputs": [],
   "source": [
    "# parameters and utility globals\n",
    "\n",
    "n_humans = 1000 # 10k for paper\n",
    "beta = 0.1 # bots/humans ratio; 0.1 for paper\n",
    "p = 0.5 # for network clustering; 0.5 for paper\n",
    "k_out = 3 # average no. friends within humans & bots; 3 for paper\n",
    "alpha = 15 # depth of feed; 15 for paper\n",
    "mu = 0.75 # average prob of new meme vs retweet; 0.75 for paper or draw from empirical distribution\n",
    "# phi = 1 # bot deception >= 1: meme fitness higher than quality\n",
    "# gamma = 0.1 # infiltration: probability that a human follows each bot\n",
    "epsilon = 0.01 # threshold used to check for steady-state convergence\n",
    "n_runs = 10 # number of simulations to average results\n",
    "cvsfile = 'results.csv' # to save results for plotting\n",
    "\n",
    "phis = [1, 5, 10] # bot deception >= 1: meme fitness higher than quality \n",
    "gammas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0] # infiltration: probability that a human follows each bot\n",
    "\n",
    "# if called with gamma as a command line params\n",
    "if len(sys.argv) == 2:\n",
    "  gamma = float(sys.argv[1])\n",
    "  assert(0 <= gamma <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqvOoIzuIJGY"
   },
   "source": [
    "Above are definitions\n",
    "\n",
    "---\n",
    "\n",
    "Below is main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T15:49:24.918797Z",
     "start_time": "2020-05-14T15:41:12.696429Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qDd3WKkdndkK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment, save results to CSV file\n",
    "# this is slow for large n_humans; better to run in parallel \n",
    "# on a server or cluster, eg, one process per gamma value\n",
    "save_dir = \"results/random\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "q_random_all = {}\n",
    "for phi in phis:\n",
    "  for gamma in gammas:\n",
    "    q_random = []\n",
    "    valid_tracked_memes_random_all = []\n",
    "    bad_memes_selected_time_random_all = {}\n",
    "    avg_quality_random_all = []\n",
    "    avg_diversity_random_all = []\n",
    "    for sim in range(n_runs):\n",
    "      print('Running Simulation ', sim, ' for phi = ', phi, ', gamma = ', gamma, ' ...', flush=True)\n",
    "    \n",
    "      # simulation start\n",
    "      qr, qr_net = simulation(False, True, True, True, True) # random attach\n",
    "      q_random.append(qr)\n",
    "      if (phi, gamma) not in q_random_all:\n",
    "        q_random_all[(phi, gamma)] = []\n",
    "      q_random_all[(phi, gamma)].append(qr)\n",
    "    \n",
    "      #### statistic current nth-run data ####\n",
    "      ## tracked meme ##\n",
    "      valid_tracked_memes = []\n",
    "      for meme in track_memes.tracked_memes:\n",
    "        valid = True\n",
    "        for agent in qr_net.nodes:\n",
    "          for m in qr_net.nodes[agent]['feed']:\n",
    "            if meme == m:\n",
    "              valid = False\n",
    "        if valid:\n",
    "          valid_tracked_memes.append((meme[0], track_memes.tracked_memes[meme]))\n",
    "      valid_tracked_memes_random_all.extend(valid_tracked_memes)\n",
    "      ## end tracked meme ##\n",
    "    \n",
    "      ## bad meme select ##\n",
    "      for meme, selected_time in select_time.bad_memes_selected_time.items():\n",
    "        if meme[1] not in bad_memes_selected_time_all:\n",
    "          bad_memes_selected_time_random_all[meme[1]] = [0, 0]\n",
    "        bad_memes_selected_time_random_all[meme[1]][0] += selected_time[0]\n",
    "        bad_memes_selected_time_random_all[meme[1]][1] += selected_time[1]\n",
    "      ## end bad meme select ##\n",
    "\n",
    "      ## avg quality ##\n",
    "      avg_quality_random_all.append(qr)\n",
    "      ## end avg quality ##\n",
    "\n",
    "      ## avg diversity ##\n",
    "      for agent in qr_net.nodes:\n",
    "        qualities = []\n",
    "        fitnesses = []\n",
    "        for m in qr_net.nodes[agent]['feed']:\n",
    "          qualities.append(m[0])\n",
    "          fitnesses.append(m[1])\n",
    "        unique_qua, unique_qua_cnt = np.unique(qualities, return_counts=True)\n",
    "        portion_of_qua = unique_qua_cnt / np.sum(unique_qua_cnt)\n",
    "        diversity = - np.sum(portion_of_qua * np.log(portion_of_qua))\n",
    "        avg_diversity_random_all.append(diversity)\n",
    "        \n",
    "        # unique_fit, unique_fit_cnt = np.unique(fitnesses, return_counts=True)\n",
    "        # portion_of_fit = unique_fit_cnt / np.sum(unique_fit_cnt)\n",
    "        # diversity = - np.sum(portion_of_fit * np.log(portion_of_fit))\n",
    "        # avg_diversity_random_all.append(diversity)\n",
    "      ## end avg diversity ##\n",
    "      #### end statistic current nth-run data ####\n",
    "\n",
    "    for fitness, selected_time in bad_memes_selected_time_all.items():\n",
    "      bad_memes_selected_time_all[fitness][0] /= n_runs\n",
    "      bad_memes_selected_time_all[fitness][1] /= n_runs\n",
    "\n",
    "    # save tracked memes\n",
    "    fp = open(\"{}/tracked_memes_random_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(valid_tracked_memes_random_all, fp)\n",
    "    fp.close()\n",
    "\n",
    "    # save bad meme selected times\n",
    "    fp = open(\"{}/bad_memes_selected_time_random_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(bad_memes_selected_time_random_all, fp)\n",
    "    fp.close()\n",
    "\n",
    "    # save avg_quality\n",
    "    fp = open(\"{}/avg_quality_random_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(np.mean(avg_quality_random_all), fp)\n",
    "    fp.close()\n",
    "    \n",
    "    # save avg_fitness\n",
    "    fp = open(\"{}/avg_diversity_random_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(np.mean(avg_diversity_random_all), fp)\n",
    "    fp.close()\n",
    "\n",
    "    # save kendall\n",
    "    quality, number_selected = zip(*valid_tracked_memes_random_all)\n",
    "    kendall_tau, _ = stats.kendalltau(quality, number_selected)\n",
    "    fp = open(\"{}/kendall_random_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(kendall_tau, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T15:58:08.398057Z",
     "start_time": "2020-05-14T15:49:25.397948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = \"results/prefer\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "q_prefer_all = {}\n",
    "for phi in phis:\n",
    "  for gamma in gammas:\n",
    "    q_prefer = []\n",
    "    valid_tracked_memes_prefer_all = []\n",
    "    bad_memes_selected_time_prefer_all = {}\n",
    "    avg_quality_prefer_all = []\n",
    "    avg_diversity_prefer_all = []\n",
    "    for sim in range(n_runs):\n",
    "      print('Running Simulation ', sim, ' for phi = ', phi, ', gamma = ', gamma, ' ...', flush=True)\n",
    "\n",
    "      # simulation start\n",
    "      qp, qp_net = simulation(True, True, True, True, True) # preferential attach\n",
    "      q_prefer.append(qp)\n",
    "      if (phi, gamma) not in q_prefer_all:\n",
    "        q_prefer_all[(phi, gamma)] = []\n",
    "      q_prefer_all[(phi, gamma)].append(qp)\n",
    "    \n",
    "      #### statistic current nth-run data ####\n",
    "      ## tracked meme ##\n",
    "      valid_tracked_memes = []\n",
    "      for meme in track_memes.tracked_memes:\n",
    "        valid = True\n",
    "        for agent in qr_net.nodes:\n",
    "          for m in qr_net.nodes[agent]['feed']:\n",
    "            if meme == m:\n",
    "              valid = False\n",
    "        if valid:\n",
    "          valid_tracked_memes.append((meme[0], track_memes.tracked_memes[meme]))\n",
    "      valid_tracked_memes_prefer_all.extend(valid_tracked_memes)\n",
    "      ## end tracked meme ##\n",
    "    \n",
    "      ## bad meme select ##\n",
    "      for meme, selected_time in select_time.bad_memes_selected_time.items():\n",
    "        if meme[1] not in bad_memes_selected_time_all:\n",
    "          bad_memes_selected_time_prefer_all[meme[1]] = [0, 0]\n",
    "        bad_memes_selected_time_prefer_all[meme[1]][0] += selected_time[0]\n",
    "        bad_memes_selected_time_prefer_all[meme[1]][1] += selected_time[1]\n",
    "      ## end bad meme select ##\n",
    "\n",
    "      ## avg quality ##\n",
    "      avg_quality_prefer_all.append(qp)\n",
    "      ## end avg quality ##\n",
    "\n",
    "      ## avg diversity ##\n",
    "      for agent in qp_net.nodes:\n",
    "        qualities = []\n",
    "        fitnesses = []\n",
    "        for m in qp_net.nodes[agent]['feed']:\n",
    "          qualities.append(m[0])\n",
    "          fitnesses.append(m[1])\n",
    "        unique_qua, unique_qua_cnt = np.unique(qualities, return_counts=True)\n",
    "        portion_of_qua = unique_qua_cnt / np.sum(unique_qua_cnt)\n",
    "        diversity = - np.sum(portion_of_qua * np.log(portion_of_qua))\n",
    "        avg_diversity_prefer_all.append(diversity)\n",
    "        \n",
    "        # unique_fit, unique_fit_cnt = np.unique(fitnesses, return_counts=True)\n",
    "        # portion_of_fit = unique_fit_cnt / np.sum(unique_fit_cnt)\n",
    "        # diversity = - np.sum(portion_of_fit * np.log(portion_of_fit))\n",
    "        # avg_diversity_prefer_all.append(diversity)\n",
    "      ## end avg diversity ##\n",
    "      #### end statistic current nth-run data ####\n",
    "\n",
    "    for fitness, selected_time in bad_memes_selected_time_all.items():\n",
    "      bad_memes_selected_time_all[fitness][0] /= n_runs\n",
    "      bad_memes_selected_time_all[fitness][1] /= n_runs\n",
    "\n",
    "    # save tracked memes\n",
    "    fp = open(\"{}/tracked_memes_prefer_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(valid_tracked_memes_prefer_all, fp)\n",
    "    fp.close()\n",
    "\n",
    "    # save bad meme selected times\n",
    "    fp = open(\"{}/bad_memes_selected_time_prefer_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(bad_memes_selected_time_prefer_all, fp)\n",
    "    fp.close()\n",
    "\n",
    "    # save avg_quality\n",
    "    fp = open(\"{}/avg_quality_prefer_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(np.mean(avg_quality_prefer_all), fp)\n",
    "    fp.close()\n",
    "    \n",
    "    # save avg_fitness\n",
    "    fp = open(\"{}/avg_diversity_prefer_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(np.mean(avg_diversity_prefer_all), fp)\n",
    "    fp.close()\n",
    "\n",
    "    # save kendall\n",
    "    quality, number_selected = zip(*valid_tracked_memes_prefer_all)\n",
    "    kendall_tau, _ = stats.kendalltau(quality, number_selected)\n",
    "    fp = open(\"{}/kendall_prefer_phi{}_gamma{}.pkl\".format(save_dir, phi, gamma), \"wb\")\n",
    "    pickle.dump(kendall_tau, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T15:58:13.284621Z",
     "start_time": "2020-05-14T15:58:13.269804Z"
    }
   },
   "outputs": [],
   "source": [
    "q_ratio = []\n",
    "\n",
    "for phi in phis:\n",
    "  for gamma in gammas:\n",
    "    q_random = q_random_all[(phi, gamma)]\n",
    "    q_preferential = q_prefer_all[(phi, gamma)]\n",
    "    q_ratio = (np.array(q_preferential) / np.array(q_random)).tolist()\n",
    "    # save results to CSV file\n",
    "    save_csv([gamma, statistics.mean(q_random), \n",
    "            statistics.stdev(q_random) / math.sqrt(n_runs), \n",
    "            statistics.mean(q_preferential), \n",
    "            statistics.stdev(q_preferential) / math.sqrt(n_runs), \n",
    "            statistics.mean(q_ratio), \n",
    "            statistics.stdev(q_ratio) / math.sqrt(n_runs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T15:58:16.564851Z",
     "start_time": "2020-05-14T15:58:16.031528Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "atc5bUxE0Trf"
   },
   "outputs": [],
   "source": [
    "# plot data from CSV file\n",
    "\n",
    "q_mean_random, q_stderr_random, q_mean_preferential, q_stderr_preferential, q_mean_ratio, q_stderr_ratio = read_csv('results.csv')\n",
    "\n",
    "ymin = [q_mean_ratio[x] - q_stderr_ratio[x] for x in q_mean_ratio.keys()]\n",
    "ymax = [q_mean_ratio[x] + q_stderr_ratio[x] for x in q_mean_ratio.keys()]\n",
    "plt.xlabel(r'$\\gamma$', fontsize=16)\n",
    "plt.ylabel('Average Quality Ratio', fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.axhline(y=1, lw=0.5, color='black')\n",
    "plt.plot(list(q_mean_ratio.keys()), list(q_mean_ratio.values()))\n",
    "plt.fill_between(list(q_mean_ratio.keys()), ymax, ymin, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T15:58:21.623637Z",
     "start_time": "2020-05-14T15:58:20.816659Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "-NjCcdb424_q",
    "outputId": "80c1806e-9636-4f30-a04a-1f00d0626bb0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot from files for different values of mu\n",
    "\n",
    "plt.subplots(figsize=plt.figaspect(1.5))\n",
    "\n",
    "_, _, _, _, ratio_mu75, stderr_mu75 = read_csv('results.csv')\n",
    "ymin_mu75 = [ratio_mu75[x] - 2*stderr_mu75[x] for x in ratio_mu75.keys()]\n",
    "ymax_mu75 = [ratio_mu75[x] + 2*stderr_mu75[x] for x in ratio_mu75.keys()]\n",
    "plt.plot(list(ratio_mu75.keys()), list(ratio_mu75.values()), label=r'$\\mu=0.75$')\n",
    "plt.fill_between(list(ratio_mu75.keys()), ymax_mu75, ymin_mu75, alpha=0.2)\n",
    "\n",
    "_, _, _, _, ratio_mu25, stderr_mu25 = read_csv('results.csv')\n",
    "ymin_mu25 = [ratio_mu25[x] - 2*stderr_mu25[x] for x in ratio_mu25.keys()]\n",
    "ymax_mu25 = [ratio_mu25[x] + 2*stderr_mu25[x] for x in ratio_mu25.keys()]\n",
    "plt.plot(list(ratio_mu25.keys()), list(ratio_mu25.values()), label=r'$\\mu=0.25$')\n",
    "plt.fill_between(list(ratio_mu25.keys()), ymax_mu25, ymin_mu25, alpha=0.2)\n",
    "\n",
    "plt.xlabel(r'$\\gamma$', fontsize=16)\n",
    "plt.ylabel('Average Quality Ratio', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.axhline(y=1, lw=0.5, color='black')\n",
    "plt.legend(fontsize=14, loc='upper center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_targeting.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDTP02u76ZmW"
   },
   "source": [
    "Above is main experiment\n",
    "\n",
    "---\n",
    "\n",
    "Everything below is supplementary testing and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T15:25:56.755433Z",
     "start_time": "2020-05-25T15:25:54.671993Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot Fig3\n",
    "\n",
    "xs = phis\n",
    "ys = gammas\n",
    "phis1 = phis\n",
    "phis2 = phis\n",
    "wires = gammas\n",
    "new_wires = gammas\n",
    "cmap = None\n",
    "xlabel = '$\\\\phi$'\n",
    "ylabel = '$\\\\gamma$'\n",
    "\n",
    "kendall_pic_title = 'Discriminative power'\n",
    "avg_quality_pic_title = 'Average Quality'\n",
    "diversity_pic_title = 'Diversity'\n",
    "\n",
    "figure = plt.figure(figsize=(13, 15), facecolor='w')\n",
    "markers = [\"o\", \"s\", \"^\"]\n",
    "\n",
    "save_dir = \"results/prefer\"\n",
    "\n",
    "### 1. average quality ###\n",
    "if save_dir == \"results/random\":\n",
    "    file_template = \"{}/avg_quality_random_phi{}_gamma{}.pkl\"\n",
    "else:\n",
    "    file_template = \"{}/avg_quality_prefer_phi{}_gamma{}.pkl\"\n",
    "\n",
    "# distr plot\n",
    "ax = figure.add_subplot(3,2,1)\n",
    "for idx, phi in enumerate(phis1):\n",
    "    avg_qualities = []\n",
    "    stds = []\n",
    "    for gamma in wires:\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        avg_qualities.append(np.mean(data))\n",
    "        stds.append(np.std(data))\n",
    "    ax.plot(new_wires, avg_qualities, marker=markers[idx], label='$\\\\phi$:'+str(h))\n",
    "\n",
    "ax.set_xlabel('$\\\\gamma$', fontsize=14)\n",
    "ax.set_ylabel('Average quality', fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim((new_wires[0], new_wires[-1]))\n",
    "ax.set_xlim((new_wires[0], new_wires[-1]))\n",
    "ax.legend(loc='upper right', fontsize=14)\n",
    "\n",
    "# heatmap plot\n",
    "ax = figure.add_subplot(3,2,2)\n",
    "grid = np.zeros((len(wires), len(phis2)))\n",
    "for i, gamma in enumerate(wires):\n",
    "    for j, phi in enumerate(phis2):\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        grid[i, j] = np.mean(data)\n",
    "draw_heatmap(ax, grid, xs, ys, xlabel, ylabel, cmap, avg_quality_pic_title, vmin=None, vmax=None)\n",
    "\n",
    "\n",
    "### 2. average diversity ###\n",
    "if save_dir == \"results/random\":\n",
    "    file_template = \"{}/avg_diversity_prefer_phi{}_gamma{}.pkl\"\n",
    "else:\n",
    "    file_template = \"{}/avg_diversity_prefer_phi{}_gamma{}.pkl\"\n",
    "\n",
    "# distr plot\n",
    "ax = figure.add_subplot(3,2,3)\n",
    "for idx, phi in enumerate(phis1):\n",
    "    avg_diversities = []\n",
    "    stds = []\n",
    "    for gamma in wires:\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        avg_diversities.append(np.mean(data))\n",
    "        stds.append(np.std(data))\n",
    "    ax.plot(new_wires, avg_diversities, marker=markers[idx], label='$\\\\phi$:'+str(h))\n",
    "\n",
    "ax.set_xlabel('$\\\\gamma$', fontsize=14)\n",
    "ax.set_ylabel('Diversity', fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim((new_wires[0], new_wires[-1]))\n",
    "ax.set_xlim((new_wires[0], new_wires[-1]))\n",
    "\n",
    "# heatmap plot\n",
    "ax = figure.add_subplot(3,2,4)\n",
    "grid = np.zeros((len(wires), len(phis2)))\n",
    "for i, gamma in enumerate(wires):\n",
    "    for j, phi in enumerate(phis2):\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        grid[i, j] = np.mean(data)\n",
    "draw_heatmap(ax, grid, xs, ys, xlabel, ylabel, cmap, diversity_pic_title, vmin=None, vmax=None)\n",
    "\n",
    "### 3. kendall ###\n",
    "if save_dir == \"results/random\":\n",
    "    file_template = \"{}/kendall_random_phi{}_gamma{}.pkl\"\n",
    "else:\n",
    "    file_template = \"{}/kendall_prefer_phi{}_gamma{}.pkl\"\n",
    "\n",
    "# distr plot\n",
    "ax = figure.add_subplot(3,2,5)\n",
    "for idx, phi in enumerate(phis1):\n",
    "    kendalls = []\n",
    "    stds = []\n",
    "    for gamma in wires:\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        kendalls.append(np.mean(data))\n",
    "        stds.append(np.std(data))\n",
    "    ax.plot(new_wires, kendalls, marker=markers[idx], label='$\\\\phi$:'+str(h))\n",
    "\n",
    "ax.set_xlabel('$\\\\gamma$', fontsize=14)\n",
    "ax.set_ylabel('Discriminative power', fontsize=14)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim((new_wires[0], new_wires[-1]))\n",
    "ax.set_xlim((new_wires[0], new_wires[-1]))\n",
    "# ax.legend(loc='lower left', fontsize=14)\n",
    "\n",
    "# heatmap plot\n",
    "ax = figure.add_subplot(3,2,6)\n",
    "grid = np.zeros((len(wires), len(phis2)))\n",
    "for i, gamma in enumerate(wires):\n",
    "    for j, phi in enumerate(phis2):\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        grid[i, j] = np.mean(data)\n",
    "draw_heatmap(ax, grid, xs, ys, xlabel, ylabel, cmap, kendall_pic_title, vmin=None, vmax=None)\n",
    "\n",
    "### 4. save plot ###\n",
    "plt.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.05, wspace=0.3, hspace=0.3)\n",
    "plt.savefig(save_dir + \"/all_distr_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T16:02:49.966704Z",
     "start_time": "2020-05-14T16:02:46.542128Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot Fig5\n",
    "\n",
    "save_dir = \"results/random\"\n",
    "if save_dir == \"results/random\":\n",
    "    file_template = \"{}/tracked_memes_random_phi{}_gamma{}.pkl\"\n",
    "else:\n",
    "    file_template = \"{}/tracked_memes_prefer_phi{}_gamma{}.pkl\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(14, 8))\n",
    "for i, phi in enumerate([1, 10]):\n",
    "    for j, gamma in enumerate([0.001, 0.005, 0.01]):\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "\n",
    "        quality, number_selected = zip(*data)\n",
    "\n",
    "        low_quality_pop = []\n",
    "        high_quality_pop = []\n",
    "        for qua, pop in zip(quality, number_selected):\n",
    "            if qua > 0:\n",
    "                high_quality_pop.append(pop)\n",
    "            else:\n",
    "                low_quality_pop.append(pop)\n",
    "\n",
    "        count = get_count(high_quality_pop)\n",
    "        distr, sum_ = get_distr(count)\n",
    "        h_mids, h_heights = getbins(distr, sum_)\n",
    "\n",
    "        count = get_count(low_quality_pop)\n",
    "        distr, sum_ = get_distr(count)\n",
    "        l_mids, l_heights = getbins(distr, sum_)\n",
    "\n",
    "        h_dict = defaultdict(list)\n",
    "        for hm, hh in zip(h_mids, h_heights):\n",
    "            h_dict[hm].append(hh)\n",
    "        l_dict = defaultdict(list)\n",
    "        for lm, lh in zip(l_mids, l_heights):\n",
    "            l_dict[lm].append(lh)\n",
    "\n",
    "        hs = []\n",
    "        for k, v in h_dict.items():\n",
    "            hs.append([k, np.mean(v)])\n",
    "        h_mids, h_heights = zip(*sorted(hs, key=lambda x:x[0]))\n",
    "        ls = []\n",
    "        for k, v in l_dict.items():\n",
    "            ls.append([k, np.mean(v)])\n",
    "        l_mids, l_heights = zip(*sorted(ls, key=lambda x:x[0]))\n",
    "\n",
    "        ax = axs[i][j]\n",
    "        ax.loglog(h_mids, h_heights, marker='s', label='high quality')\n",
    "        ax.loglog(l_mids, l_heights, marker='^', label='low quality')\n",
    "        ax.set_xlabel('popularity', fontsize=14)\n",
    "        ax.set_ylabel('P(popularity)', fontsize=14)\n",
    "        ax.tick_params(labelsize=14)\n",
    "        ax.annotate('$\\\\gamma={}$\\n$\\\\phi={}$'.format(gamma, phi), xy=(0.05, 0.05), xycoords='axes fraction', fontsize=12)\n",
    "        if i == 0 and j == 0:\n",
    "            ax.legend(loc=\"upper right\", fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(left=0.08, right=0.92, top=0.92, wspace=0.3, hspace=0.3)\n",
    "plt.show()\n",
    "plt.savefig(save_dir + \"meme_quality_random_distr.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T15:26:19.203080Z",
     "start_time": "2020-05-25T15:26:18.292723Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot Fig6\n",
    "\n",
    "save_dir = \"results/random\"\n",
    "if save_dir == \"results/random\":\n",
    "    file_template = \"{}/bad_memes_selected_time_random_phi{}_gamma{}.pkl\"\n",
    "else:\n",
    "    file_template = \"{}/bad_memes_selected_time_prefer_phi{}_gamma{}.pkl\"\n",
    "\n",
    "for i, phi in enumerate([1]):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for j, gamma in enumerate([0.001]): #[0.5]\n",
    "        fname = file_template.format(save_dir, phi, gamma)\n",
    "        fp = open(fname, \"rb\")\n",
    "        data = pickle.load(fp)\n",
    "        fp.close()\n",
    "        \n",
    "        good_selected = []\n",
    "        bad_selected = []\n",
    "        for _, value in data.items():\n",
    "            if value[0] <= 0 or value[1] <= 0:\n",
    "                continue\n",
    "            good_selected.append(value[0])\n",
    "            bad_selected.append(value[1])\n",
    "\n",
    "        count = dict([val for val in zip(bad_selected, good_selected)])\n",
    "        distr_x, distr_y = get_distr(count)\n",
    "        mids, heights = getbins(distr_x, distr_y)\n",
    "        ratios = [np.log(height_)/np.log(mid_) for height_, mid_ in zip(heights, mids)]\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.loglog(mids, heights, marker='o', label='$\\\\gamma$:'+str(gamma))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(mids, ratios, marker='o', label='$\\\\gamma$:'+str(gamma))\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    # save fig\n",
    "    plt.subplot(121)\n",
    "    plt.loglog([min(mids), max(mids)], [min(mids), max(mids)], '--')\n",
    "    plt.xlabel(\"Bot posts per meme\", fontsize=14)\n",
    "    plt.ylabel(\"Human posts per meme\", fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.margins(0.1)\n",
    "    plt.legend(loc='best', fontsize=14)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.xlabel(\"Bot posts per meme\", fontsize=14)\n",
    "    plt.ylabel(\"Exponent $\\\\eta$\", fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.margins(0.1)\n",
    "    plt.legend(loc='best', fontsize=14)\n",
    "\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.14, wspace=0.4)\n",
    "    plt.show()\n",
    "    plt.savefig(save_dir + \"bad_meme_selected_random_distr_{}\".format(phi))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bot_model_xiaodan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
